[directories]
training = "data/train"
datasets = "data/sets"

[files]
training = 'data/train/data.txt'

[preperation]
sets = ["chatterbot"]

[tokenizer]
production = 'tokenizer/p_tokenizer_pi.obj'
oov_token  = 1
max_word_count = 30
num_words = 2000

[model]
production = 'models/production.h5'

[training]
batch_size = 20
epochs = 1000